{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJVo_xMPf4LY"
      },
      "source": [
        "![TrainingNotebookLogo.png](https://downloads.limelightvision.io/content/TrainingNotebookLogo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72xbzFQrPL5q"
      },
      "source": [
        "To train a neural object detector for Limelight, click the \"play\" button on each code block. Pay extra attention to any \"❗\" you see. By the end of this tutorial, you will have downloaded a .zip file containing your model and label files.\n",
        "\n",
        "See https://docs.limelightvision.io/docs/docs-limelight/pipeline-neural/training-your-own-detector for a more in-depth tutorial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05N8FeXHcQp3"
      },
      "source": [
        "# 1. Install The Object Detection Package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ypWGYdPlLRUN",
        "outputId": "e1c4451c-8394-46f8-c651-11873b90c2dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 4305, done.\u001b[K\n",
            "remote: Counting objects: 100% (4305/4305), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3293/3293), done.\u001b[K\n",
            "remote: Total 4305 (delta 1209), reused 2179 (delta 939), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (4305/4305), 53.17 MiB | 39.62 MiB/s, done.\n",
            "Resolving deltas: 100% (1209/1209), done.\n",
            "remote: Enumerating objects: 3041, done.\u001b[K\n",
            "remote: Counting objects: 100% (3041/3041), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1352/1352), done.\u001b[K\n",
            "remote: Total 1817 (delta 1216), reused 701 (delta 446), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (1817/1817), 10.05 MiB | 19.26 MiB/s, done.\n",
            "Resolving deltas: 100% (1216/1216), completed with 732 local objects.\n",
            "From https://github.com/tensorflow/models\n",
            " * branch            ad1f7b56943998864db8f5db0706950e93bb7d81 -> FETCH_HEAD\n",
            "Note: switching to 'ad1f7b56943998864db8f5db0706950e93bb7d81'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at ad1f7b5 adjust folder path\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import os\n",
        "tmpModelPath ='/content/models'\n",
        "if os.path.exists(tmpModelPath) and os.path.isdir(tmpModelPath):\n",
        "  shutil.rmtree(tmpModelPath)\n",
        "\n",
        "MLENVIRONMENT=\"COLAB\"\n",
        "!git clone --depth 1 https://github.com/tensorflow/models\n",
        "!cd models && git fetch --depth 1 origin ad1f7b56943998864db8f5db0706950e93bb7d81 && git checkout ad1f7b56943998864db8f5db0706950e93bb7d81"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6QPmVBSlLTzM",
        "outputId": "9dfdbf99-9c5f-4f72-da8e-7c3511029ffb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]\n",
            "colab env setup\n",
            "/content/\n",
            "/content/models/research\n"
          ]
        }
      ],
      "source": [
        "# Environment Setup\n",
        "import os\n",
        "import sys\n",
        "import re\n",
        "\n",
        "print(sys.version)\n",
        "if(MLENVIRONMENT == \"COLAB\"):\n",
        "    print(\"colab env setup\")\n",
        "    os.environ[\"HOMEFOLDER\"] = \"/content/\"\n",
        "    HOMEFOLDER = '{HOMEFOLDER}'.format(**os.environ)\n",
        "    FINALOUTPUTFOLDER_DIRNAME = 'final_output'\n",
        "    FINALOUTPUTFOLDER = HOMEFOLDER+FINALOUTPUTFOLDER_DIRNAME\n",
        "    print(HOMEFOLDER)\n",
        "\n",
        "# Copy setup files into models/research folder\n",
        "!cd {HOMEFOLDER}models/research && pwd && protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# Modify setup.py\n",
        "with open(HOMEFOLDER+'models/research/object_detection/packages/tf2/setup.py') as f:\n",
        "    s = f.read()\n",
        "\n",
        "with open(HOMEFOLDER+'models/research/setup.py', 'w') as f:\n",
        "    if(MLENVIRONMENT == \"COLAB\"):\n",
        "        s = re.sub('tf-models-official>=2.5.1','tf-models-official==2.15.0', s)\n",
        "        f.write(s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OLDnCkLLwLr6",
        "outputId": "faf59c38-98f1-4ce7-99db-92d37f0bec84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.10.2)\n",
            "Requirement already satisfied: apache-beam in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.60.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (11.0.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (5.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.8.0)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.0.11)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.0.8)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (0.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.2.2)\n",
            "Requirement already satisfied: tf-models-official==2.15.0 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: sacrebleu<=2.2.0 in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.2.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (2.151.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (4.2.0)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (1.6.17)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (1.26.4)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (4.10.0.84)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (6.0.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (4.9.6)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (0.16.1)\n",
            "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-text~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: tensorflow~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2024.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2.10.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\n",
            "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.7)\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.10.11)\n",
            "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.3.1.1)\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.2.1)\n",
            "Requirement already satisfied: fastavro<2,>=0.23.6 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.9.7)\n",
            "Requirement already satisfied: fasteners<1.0,>=0.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.19)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.65.5)\n",
            "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.7.3)\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/lib/python3/dist-packages (from apache-beam->object_detection==0.1) (0.20.2)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.23.0)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.4.2)\n",
            "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.7.0)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (24.1)\n",
            "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.10.1)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.25.5)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: redis<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (5.2.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.12.2)\n",
            "Requirement already satisfied: zstandard<1,>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.23.0)\n",
            "Requirement already satisfied: pyarrow<17.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.6)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (1.4.7)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (4.10.0.84)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (1.3.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (4.54.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object_detection==0.1) (0.37.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object_detection==0.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object_detection==0.1) (2.22.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object_detection==0.1) (4.1.1)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1) (0.6.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.20.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (2024.8.30)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (6.2.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1) (2.7.0)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (5.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.10)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (3.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (75.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (2.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.6.0->tf-models-official==2.15.0->object_detection==0.1) (2.15.1)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.15.0->object_detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.15.0->object_detection==0.1) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.15.0->object_detection==0.1) (0.4.1)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.15.0->object_detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.15.0->object_detection==0.1) (1.5.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (8.1.7)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (2.3)\n",
            "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (0.1.6)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (1.13.1)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (1.10.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (0.44.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (2024.10.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (3.20.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.15.0->object_detection==0.1) (1.65.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.15.0->object_detection==0.1) (5.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.15.0->object_detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.15.0->object_detection==0.1) (3.5.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (3.0.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (1.3)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (0.16)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (3.0.2)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object_detection\n",
            "  Building wheel for object_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=1697351 sha256=3b895f08ffdd70b7d176a16e2bdbbc35862546fecdb8566c874081c4d76d6908\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bqz01wav/wheels/53/dd/70/2de274d6c443c69d367bd6a5606f95e5a6df61aacf1435ec0d\n",
            "Successfully built object_detection\n",
            "Installing collected packages: object_detection\n",
            "  Attempting uninstall: object_detection\n",
            "    Found existing installation: object_detection 0.1\n",
            "    Uninstalling object_detection-0.1:\n",
            "      Successfully uninstalled object_detection-0.1\n",
            "Successfully installed object_detection-0.1\n",
            "Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.25.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.65.5)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.44.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "# Install\n",
        "!pip install {HOMEFOLDER}models/research/\n",
        "if(MLENVIRONMENT == \"COLAB\"):\n",
        "    !pip install tensorflow==2.15.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6V7TrfUos-9E"
      },
      "source": [
        "Test the environment by running `model_builder_tf2_test.py` to make sure everything is working as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wh_HPMOqWH9z",
        "outputId": "0a5867c7-4c2b-432c-ea63-5417c246647c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-11-08 21:11:16.814977: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:95] Opening library: /usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/../../libtensorflow_cc.so.2\n",
            "2024-11-08 21:11:16.815168: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:119] Libtpu path is: libtpu.so\n",
            "2024-11-08 21:11:16.860757: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/models/research/object_detection/builders/model_builder_tf2_test.py\", line 24, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/builders/model_builder.py\", line 23, in <module>\n",
            "    from object_detection.builders import anchor_generator_builder\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/builders/anchor_generator_builder.py\", line 26, in <module>\n",
            "    from object_detection.protos import anchor_generator_pb2\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/protos/anchor_generator_pb2.py\", line 14, in <module>\n",
            "    from object_detection.protos import flexible_grid_anchor_generator_pb2 as object__detection_dot_protos_dot_flexible__grid__anchor__generator__pb2\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/protos/flexible_grid_anchor_generator_pb2.py\", line 36, in <module>\n",
            "    _descriptor.FieldDescriptor(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/google/protobuf/descriptor.py\", line 553, in __new__\n",
            "    _message.Message._CheckCalledFromGeneratedFile()\n",
            "TypeError: Descriptors cannot be created directly.\n",
            "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
            "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
            " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
            " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
            "\n",
            "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n"
          ]
        }
      ],
      "source": [
        "!python {HOMEFOLDER}models/research/object_detection/builders/model_builder_tf2_test.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmROIG9zaS9G"
      },
      "source": [
        "#2. Get Dataset From Google Drive\n",
        "\n",
        "❗Using the same Google account you are using for this Colab, upload your RoboFlow .tfrecord.zip to your Google Drive. Some input is required in this section❗"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TvtPNjlCHTpO"
      },
      "source": [
        "This code block will mount your entire Google Drive in the \"Files\" pane on the left-hand side of your screen.\n",
        "\n",
        "❗Click the Refresh button in the \"Files\" pane after running the code block.❗"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "tLgAPsQsfTLs",
        "outputId": "b6eaa5f4-9c33-47dd-9f7d-38c19c0e787d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "if(MLENVIRONMENT==\"COLAB\"):\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLBxE6xo52-k"
      },
      "source": [
        "❗ Run the code block, wait for the file selection interface to appear, and select your .tfrecord.zip dataset ❗\n"
      ]
    },
    {
      "source": [
        "!pip install ipyfilechooser\n",
        "from ipyfilechooser import FileChooser\n",
        "fc = FileChooser('/content/')\n",
        "display(fc)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "pvBo9BGCkWHc",
        "outputId": "9c99e6e0-cf8d-49a3-8fde-cd384cbdb369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "53ae8c4f9cd24c26b75d65ab7ccafead",
            "7f21aed3e9f7421e888e72de00d98a97",
            "bd31017e380b4ef19bc25f8fe077327a",
            "6a0602404ee24a4f87850f8d8b6832e2",
            "8264eebf02704d2193bd372d715f7490",
            "79a08daed1b84f6299609b3c4c42886e",
            "21e895fbee9c42ad8180b8b5a8528f23",
            "5eaf87940d6a4b3db612b426b77f6e32",
            "2a8322924ebd4d5fa1c7770fb48c359e",
            "eb0a9df4c05e411b95027f2147105ad2",
            "84e80be945684eabb5d7714f16aefb2d",
            "c0becbe3f6ab4c7c8c29dcea60b12961",
            "cbd958053d0f41108706cfc348fc5671",
            "2da585aebf474d3da9d76610d3601b1b",
            "4e9d35a17ad74b42b73a10eb41ebe697",
            "a1472b4742154086be39d546dc4a360c",
            "2e02fcf1c9474bdc825b47637ab4755e",
            "e4a5692326ee4840b34682ded1883ab2",
            "dde2476c923b446281bd90cb2f036b16",
            "e2271f199d564c2f9b7ed191688eaf21",
            "2153a994e98141b1bdb7e850fcca8581",
            "a43c305d6b24411ea43b382b85f6e46b",
            "9f121a4fba364e4b959defcd412fa30c",
            "309f6b9c90074ee5a6394b87c757aa94",
            "799f079d3b304381822c794487192035",
            "54a9ec73bb5848558026ebcc770c8e4e",
            "5ee6ae42e9a74992b5fda023a6b3af40",
            "e4953f6b4fde45bdb1835abc6327ebd1",
            "41c63fcf14c54ee8b5d4c714587ed5ea"
          ]
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipyfilechooser in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from ipyfilechooser) (7.7.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ipyfilechooser) (5.5.6)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ipyfilechooser) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ipyfilechooser) (5.7.1)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ipyfilechooser) (3.6.10)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ipyfilechooser) (7.34.0)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->ipyfilechooser) (3.0.13)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel>=4.5.1->ipywidgets->ipyfilechooser) (6.3.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser) (75.1.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser) (5.1.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser) (3.0.48)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=4.0.0->ipywidgets->ipyfilechooser) (4.9.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.10/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (6.5.5)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->ipyfilechooser) (0.8.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (5.10.4)\n",
            "Requirement already satisfied: nbconvert>=5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (7.16.4)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (1.6.0)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->ipyfilechooser) (2.9.0.post0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->ipyfilechooser) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->ipyfilechooser) (0.2.13)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (4.3.6)\n",
            "Requirement already satisfied: notebook-shim>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (0.2.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (4.12.3)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (0.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (24.1)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (1.4.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (4.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel>=4.5.1->ipywidgets->ipyfilechooser) (1.16.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (21.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (0.5.1)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (0.20.0)\n",
            "Requirement already satisfied: jupyter-server<3,>=1.8 in /usr/local/lib/python3.10/dist-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (1.24.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (1.17.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (2.22)\n",
            "Requirement already satisfied: anyio<4,>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (3.7.1)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (1.8.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->ipyfilechooser) (1.2.2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "FileChooser(path='/content', filename='', title='', show_hidden=False, select_desc='Select', change_desc='Chan…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53ae8c4f9cd24c26b75d65ab7ccafead"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2EboTT5owV_"
      },
      "source": [
        "\n",
        "\n",
        "Unzip the selected dataset into the session's filesystem.\n",
        "\n",
        "❗Click the Refresh button after running the code block.❗\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QPtKVTufFG4C",
        "outputId": "82102211-667b-4761-d11e-fe57c3e80e5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'/content/gdrive/MyDrive/Infinite-recharge-balls-yolov5.v1i.tfrecord.zip'\n",
            "Archive:  /content/gdrive/MyDrive/Infinite-recharge-balls-yolov5.v1i.tfrecord.zip\n",
            "replace README.dataset.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: README.dataset.txt      \n",
            "replace README.roboflow.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: README.roboflow.txt     \n",
            " extracting: test/Balls.tfrecord     \n",
            "  inflating: test/Balls_label_map.pbtxt  \n",
            " extracting: train/Balls.tfrecord    \n",
            "  inflating: train/Balls_label_map.pbtxt  \n",
            " extracting: valid/Balls.tfrecord    \n",
            "  inflating: valid/Balls_label_map.pbtxt  \n"
          ]
        }
      ],
      "source": [
        "if(MLENVIRONMENT==\"COLAB\"):\n",
        "    datasetPath = '\\''+fc.selected+ '\\''\n",
        "    print(datasetPath)\n",
        "    !unzip $datasetPath"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6kMXxVJo5za"
      },
      "source": [
        "Auto-detect relevant tfrecord components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "YUd2wtfrqedy",
        "outputId": "5e8ac78a-1409-4478-9ff7-b5c935597bf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Record File: /content/train/Balls.tfrecord\n",
            "Validation Record File: /content/valid/Balls.tfrecord\n",
            "Label Map File: /content/test/Balls_label_map.pbtxt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import fnmatch\n",
        "\n",
        "def find_files(directory, pattern):\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for basename in files:\n",
        "            if fnmatch.fnmatch(basename, pattern):\n",
        "                filename = os.path.join(root, basename)\n",
        "                yield filename\n",
        "\n",
        "def set_tfrecord_variables(directory):\n",
        "    train_record_fname = ''\n",
        "    val_record_fname = ''\n",
        "    label_map_pbtxt_fname = ''\n",
        "\n",
        "    for tfrecord_file in find_files(directory, '*.tfrecord'):\n",
        "        if '/train/' in tfrecord_file:\n",
        "            train_record_fname = tfrecord_file\n",
        "        elif '/valid/' in tfrecord_file:\n",
        "            val_record_fname = tfrecord_file\n",
        "        elif '/test/' in tfrecord_file:\n",
        "            pass\n",
        "\n",
        "    for label_map_file in find_files(directory, '*_label_map.pbtxt'):\n",
        "        label_map_pbtxt_fname = label_map_file  # Assuming one common label map file\n",
        "\n",
        "    return train_record_fname, val_record_fname, label_map_pbtxt_fname\n",
        "\n",
        "train_record_fname, val_record_fname, label_map_pbtxt_fname = set_tfrecord_variables('/content')\n",
        "\n",
        "#if(MLENVIRONMENT==\"COLAB\"):\n",
        "    #train_record_fname = '/content/train/cubes-cones.tfrecord'\n",
        "    #val_record_fname = '/content/valid/cubes-cones.tfrecord'\n",
        "    #label_map_pbtxt_fname = '/content/train/cubes-cones_label_map.pbtxt'\n",
        "\n",
        "print(\"Train Record File:\", train_record_fname)\n",
        "print(\"Validation Record File:\", val_record_fname)\n",
        "print(\"Label Map File:\", label_map_pbtxt_fname)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGEUZYAMEZ6f"
      },
      "source": [
        "# 3.&nbsp;Training Configuration and Labels File Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2MAcgJ53STW"
      },
      "source": [
        "Download the pre-trained Limelight Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "gN0EUEa3e5Un",
        "outputId": "a0c7ba97-8dd8-4f1c-ef21-41120fd289f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "/content/models/mymodel\n",
            "--2024-11-08 21:13:25--  https://downloads.limelightvision.io/models/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving downloads.limelightvision.io (downloads.limelightvision.io)... 18.160.200.9, 18.160.200.95, 18.160.200.119, ...\n",
            "Connecting to downloads.limelightvision.io (downloads.limelightvision.io)|18.160.200.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46042990 (44M) [application/x-gzip]\n",
            "Saving to: ‘limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "limelight_ssd_mobil 100%[===================>]  43.91M   183MB/s    in 0.2s    \n",
            "\n",
            "2024-11-08 21:13:26 (183 MB/s) - ‘limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz’ saved [46042990/46042990]\n",
            "\n",
            "--2024-11-08 21:13:26--  https://downloads.limelightvision.io/models/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config\n",
            "Resolving downloads.limelightvision.io (downloads.limelightvision.io)... 18.160.200.9, 18.160.200.95, 18.160.200.119, ...\n",
            "Connecting to downloads.limelightvision.io (downloads.limelightvision.io)|18.160.200.9|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4681 (4.6K) [binary/octet-stream]\n",
            "Saving to: ‘limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config’\n",
            "\n",
            "limelight_ssd_mobil 100%[===================>]   4.57K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-11-08 21:13:26 (344 MB/s) - ‘limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config’ saved [4681/4681]\n",
            "\n",
            "/root\n"
          ]
        }
      ],
      "source": [
        "chosen_model = 'ssd-mobilenet-v2'\n",
        "MODELS_CONFIG = {\n",
        "    'ssd-mobilenet-v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
        "        'base_pipeline_file': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
        "        'pretrained_checkpoint': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
        "    },\n",
        "}\n",
        "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
        "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
        "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
        "\n",
        "# Create \"mymodel\" folder for pre-trained weights and configuration files\n",
        "%cd ~\n",
        "%mkdir {HOMEFOLDER}models/mymodel/\n",
        "%cd {HOMEFOLDER}models/mymodel/\n",
        "%pwd\n",
        "\n",
        "# Download pre-trained model weights\n",
        "import tarfile\n",
        "download_tar = 'https://downloads.limelightvision.io/models/' + pretrained_checkpoint\n",
        "!wget {download_tar}\n",
        "tar = tarfile.open(pretrained_checkpoint)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# Download training configuration file for model\n",
        "download_config = 'https://downloads.limelightvision.io/models/' + base_pipeline_file\n",
        "!wget {download_config}\n",
        "%cd ~\n",
        "\n",
        "# Set training parameters for the model\n",
        "num_steps = 40000\n",
        "checkpoint_every = 2000\n",
        "batch_size = 16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMbr89qqgTVW"
      },
      "source": [
        "Generate Labels File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DDyH_i3MgP1D",
        "outputId": "44d928da-8adf-4d21-fa58-c692f24ff18c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting protobuf==3.20.0\n",
            "  Using cached protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (698 bytes)\n",
            "Using cached protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "Installing collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "apache-beam 2.60.0 requires protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-api-core 2.22.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.65.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "15e0e177c3a54352b5dd4bbf92a6a8d9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total classes: 1\n",
            "['Ball']\n"
          ]
        }
      ],
      "source": [
        "!pip install protobuf==3.20.0\n",
        "# Set file locations and get number of classes for config file\n",
        "pipeline_fname = HOMEFOLDER+'models/mymodel/' + base_pipeline_file\n",
        "fine_tune_checkpoint = HOMEFOLDER+'models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
        "\n",
        "def get_num_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "    return len(category_index.keys())\n",
        "\n",
        "def get_classes(pbtxt_fname):\n",
        "    from object_detection.utils import label_map_util\n",
        "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
        "    categories = label_map_util.convert_label_map_to_categories(\n",
        "        label_map, max_num_classes=90, use_display_name=True)\n",
        "    category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "    class_names = [category['name'] for category in category_index.values()]\n",
        "    return class_names\n",
        "\n",
        "def create_label_file(filename, labels):\n",
        "    with open(filename, 'w') as file:\n",
        "        for label in labels:\n",
        "            file.write(label + '\\n')\n",
        "\n",
        "\n",
        "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
        "classes = get_classes(label_map_pbtxt_fname)\n",
        "\n",
        "print('Total classes:', num_classes)\n",
        "print(classes)\n",
        "\n",
        "\n",
        "#Generate labels file\n",
        "create_label_file(HOMEFOLDER + \"limelight_neural_detector_labels.txt\", classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwPyaIAXxyKu"
      },
      "source": [
        "Modify the base Limelight Model Configuration File\n",
        "\n",
        "Augmentation Options: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5eA5ht3_yukT",
        "outputId": "439a84f1-13b8-4ce9-f40f-96b3ae502281",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "writing custom configuration file\n",
            " \n",
            "/content/training_progress/\n"
          ]
        }
      ],
      "source": [
        "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
        "import re\n",
        "\n",
        "print('writing custom configuration file')\n",
        "\n",
        "\n",
        "\n",
        "with open(pipeline_fname) as f:\n",
        "    s = f.read()\n",
        "with open('pipeline_file.config', 'w') as f:\n",
        "\n",
        "    # Set fine_tune_checkpoint path\n",
        "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
        "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
        "\n",
        "    # Set tfrecord files for train and test datasets\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
        "    s = re.sub(\n",
        "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
        "\n",
        "    # Set label_map_path\n",
        "    s = re.sub(\n",
        "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
        "\n",
        "    # Set batch_size\n",
        "    s = re.sub('batch_size: [0-9]+',\n",
        "               'batch_size: {}'.format(batch_size), s)\n",
        "\n",
        "    # Set training steps, num_steps\n",
        "    s = re.sub('num_steps: [0-9]+',\n",
        "               'num_steps: {}'.format(num_steps), s)\n",
        "\n",
        "    # Set number of classes num_classes\n",
        "    s = re.sub('checkpoint_every_n: [0-9]+',\n",
        "               'num_classes: {}'.format(num_classes), s)\n",
        "\n",
        "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
        "    s = re.sub(\n",
        "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
        "\n",
        "    # If using ssd-mobilenet-v2, reduce learning rate\n",
        "    if chosen_model == 'ssd-mobilenet-v2':\n",
        "      s = re.sub('learning_rate_base: .8',\n",
        "                 'learning_rate_base: .004', s)\n",
        "\n",
        "      s = re.sub('warmup_learning_rate: 0.13333',\n",
        "                 'warmup_learning_rate: .0016666', s)\n",
        "\n",
        "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
        "    if chosen_model == 'efficientdet-d0':\n",
        "      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
        "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
        "      s = re.sub('min_dimension', 'height', s)\n",
        "      s = re.sub('max_dimension', 'width', s)\n",
        "\n",
        "    f.write(s)\n",
        "\n",
        "# (Optional) Display the custom configuration file's contents\n",
        "# !cat pipeline_file.config\n",
        "# Set the path to the custom config file and the directory to store training checkpoints in\n",
        "pipeline_file = 'pipeline_file.config'\n",
        "model_dir = HOMEFOLDER+'training_progress/'\n",
        "print(\" \")\n",
        "print(model_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-19zML6oEO7l"
      },
      "source": [
        "# 4.&nbsp;Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxPj_QV43qD5"
      },
      "source": [
        "Once training starts, come back and click the refresh button within the tensorboard window to check training progress.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI9iCCxoNlAL"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir '/content/training_progress/train'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejo07C1zXHzY"
      },
      "source": [
        "Fix TF 2.15 breaking changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ltvi224axv3Y",
        "outputId": "f3f9dc1c-8bbc-4259-f6ee-37a406ed039d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File /usr/local/lib/python3.10/dist-packages/tf_slim/data/tfexample_decoder.py fixed.\n"
          ]
        }
      ],
      "source": [
        "import shutil\n",
        "import re\n",
        "\n",
        "original_path = '/usr/local/lib/python3.10/dist-packages/tf_slim/data/tfexample_decoder.py'\n",
        "with open(original_path, 'r') as file:\n",
        "  content = file.read()\n",
        "  content = re.sub(r'import abc', 'import tensorflow as tf\\n\\nimport abc', content)\n",
        "  content = re.sub(r'control_flow_ops.case', 'tf.case', content)\n",
        "  content = re.sub(r'control_flow_ops.cond', 'tf.compat.v1.cond', content)\n",
        "with open(original_path, 'w') as file:\n",
        "  file.write(content)\n",
        "\n",
        "print(f\"File {original_path} fixed.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjqYo9r9ffVx"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "tQTfZChVzzpZ",
        "outputId": "b871bc5f-fa5f-401c-a169-673d58f6435b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /content/models/research/object_detection/model_main_tf2.py:100: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use distribute.MultiWorkerMirroredStrategy instead\n",
            "W1108 21:14:00.978028 138286988440000 deprecation.py:50] From /content/models/research/object_detection/model_main_tf2.py:100: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "use distribute.MultiWorkerMirroredStrategy instead\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/device:CPU:0',)\n",
            "I1108 21:14:01.010266 138286988440000 mirrored_strategy.py:423] Using MirroredStrategy with devices ('/device:CPU:0',)\n",
            "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:CPU:0',), communication = CommunicationImplementation.AUTO\n",
            "I1108 21:14:01.010492 138286988440000 collective_all_reduce_strategy.py:446] Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:CPU:0',), communication = CommunicationImplementation.AUTO\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 40000\n",
            "I1108 21:14:01.014091 138286988440000 config_util.py:552] Maybe overwriting train_steps: 40000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1108 21:14:01.014226 138286988440000 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1108 21:14:01.054059 138286988440000 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['/content/train/Balls.tfrecord']\n",
            "I1108 21:14:01.060781 138286988440000 dataset_builder.py:162] Reading unweighted datasets: ['/content/train/Balls.tfrecord']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['/content/train/Balls.tfrecord']\n",
            "I1108 21:14:01.060938 138286988440000 dataset_builder.py:79] Reading record datasets for input file: ['/content/train/Balls.tfrecord']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1108 21:14:01.060996 138286988440000 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1108 21:14:01.061044 138286988440000 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1108 21:14:01.068512 138286988440000 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1108 21:14:01.088099 138286988440000 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1108 21:14:06.893398 138286988440000 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1108 21:14:09.608917 138286988440000 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1108 21:14:11.939228 138286988440000 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2024-11-08 21:14:14.593721: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I1108 21:14:32.399591 138250559678016 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1108 21:14:34.236939 138250559678016 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1108 21:14:34.237267 138250559678016 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1108 21:14:34.237423 138250559678016 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1108 21:14:34.237525 138250559678016 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1108 21:14:34.237631 138250559678016 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I1108 21:14:34.237721 138250559678016 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\n",
            "I1108 21:14:42.118843 138250559678016 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "2024-11-08 21:14:49.703891: W tensorflow/core/framework/dataset.cc:959] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "I1108 21:14:51.497852 138251079763520 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "I1108 21:14:59.120666 138251079763520 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "I1108 21:15:05.632528 138251079763520 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "I1108 21:15:12.867788 138251079763520 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\n",
            "INFO:tensorflow:Step 100 per-step time 1.790s\n",
            "I1108 21:17:49.190287 138286988440000 model_lib_v2.py:705] Step 100 per-step time 1.790s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13648646,\n",
            " 'Loss/localization_loss': 0.28722095,\n",
            " 'Loss/regularization_loss': 0.08806952,\n",
            " 'Loss/total_loss': 0.5117769,\n",
            " 'learning_rate': 0.00178327}\n",
            "I1108 21:17:49.190689 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.13648646,\n",
            " 'Loss/localization_loss': 0.28722095,\n",
            " 'Loss/regularization_loss': 0.08806952,\n",
            " 'Loss/total_loss': 0.5117769,\n",
            " 'learning_rate': 0.00178327}\n",
            "INFO:tensorflow:Step 200 per-step time 1.180s\n",
            "I1108 21:19:47.188979 138286988440000 model_lib_v2.py:705] Step 200 per-step time 1.180s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07614521,\n",
            " 'Loss/localization_loss': 0.1256504,\n",
            " 'Loss/regularization_loss': 0.08806735,\n",
            " 'Loss/total_loss': 0.28986296,\n",
            " 'learning_rate': 0.0018999401}\n",
            "I1108 21:19:47.189372 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.07614521,\n",
            " 'Loss/localization_loss': 0.1256504,\n",
            " 'Loss/regularization_loss': 0.08806735,\n",
            " 'Loss/total_loss': 0.28986296,\n",
            " 'learning_rate': 0.0018999401}\n",
            "INFO:tensorflow:Step 300 per-step time 1.154s\n",
            "I1108 21:21:42.634940 138286988440000 model_lib_v2.py:705] Step 300 per-step time 1.154s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08889053,\n",
            " 'Loss/localization_loss': 0.1279778,\n",
            " 'Loss/regularization_loss': 0.08806147,\n",
            " 'Loss/total_loss': 0.3049298,\n",
            " 'learning_rate': 0.00201661}\n",
            "I1108 21:21:42.635346 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.08889053,\n",
            " 'Loss/localization_loss': 0.1279778,\n",
            " 'Loss/regularization_loss': 0.08806147,\n",
            " 'Loss/total_loss': 0.3049298,\n",
            " 'learning_rate': 0.00201661}\n",
            "INFO:tensorflow:Step 400 per-step time 1.149s\n",
            "I1108 21:23:37.519623 138286988440000 model_lib_v2.py:705] Step 400 per-step time 1.149s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.084057994,\n",
            " 'Loss/localization_loss': 0.11491811,\n",
            " 'Loss/regularization_loss': 0.08805243,\n",
            " 'Loss/total_loss': 0.28702852,\n",
            " 'learning_rate': 0.00213328}\n",
            "I1108 21:23:37.519974 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.084057994,\n",
            " 'Loss/localization_loss': 0.11491811,\n",
            " 'Loss/regularization_loss': 0.08805243,\n",
            " 'Loss/total_loss': 0.28702852,\n",
            " 'learning_rate': 0.00213328}\n",
            "INFO:tensorflow:Step 500 per-step time 1.150s\n",
            "I1108 21:25:32.486228 138286988440000 model_lib_v2.py:705] Step 500 per-step time 1.150s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08237597,\n",
            " 'Loss/localization_loss': 0.08728057,\n",
            " 'Loss/regularization_loss': 0.088043526,\n",
            " 'Loss/total_loss': 0.2577001,\n",
            " 'learning_rate': 0.00224995}\n",
            "I1108 21:25:32.486618 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.08237597,\n",
            " 'Loss/localization_loss': 0.08728057,\n",
            " 'Loss/regularization_loss': 0.088043526,\n",
            " 'Loss/total_loss': 0.2577001,\n",
            " 'learning_rate': 0.00224995}\n",
            "INFO:tensorflow:Step 600 per-step time 1.143s\n",
            "I1108 21:27:26.834233 138286988440000 model_lib_v2.py:705] Step 600 per-step time 1.143s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07320088,\n",
            " 'Loss/localization_loss': 0.037679274,\n",
            " 'Loss/regularization_loss': 0.08803177,\n",
            " 'Loss/total_loss': 0.19891192,\n",
            " 'learning_rate': 0.00236662}\n",
            "I1108 21:27:26.834591 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.07320088,\n",
            " 'Loss/localization_loss': 0.037679274,\n",
            " 'Loss/regularization_loss': 0.08803177,\n",
            " 'Loss/total_loss': 0.19891192,\n",
            " 'learning_rate': 0.00236662}\n",
            "INFO:tensorflow:Step 700 per-step time 1.135s\n",
            "I1108 21:29:20.363241 138286988440000 model_lib_v2.py:705] Step 700 per-step time 1.135s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0679762,\n",
            " 'Loss/localization_loss': 0.031160457,\n",
            " 'Loss/regularization_loss': 0.088019766,\n",
            " 'Loss/total_loss': 0.18715642,\n",
            " 'learning_rate': 0.0024832902}\n",
            "I1108 21:29:20.363612 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.0679762,\n",
            " 'Loss/localization_loss': 0.031160457,\n",
            " 'Loss/regularization_loss': 0.088019766,\n",
            " 'Loss/total_loss': 0.18715642,\n",
            " 'learning_rate': 0.0024832902}\n",
            "INFO:tensorflow:Step 800 per-step time 1.115s\n",
            "I1108 21:31:11.898768 138286988440000 model_lib_v2.py:705] Step 800 per-step time 1.115s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06971646,\n",
            " 'Loss/localization_loss': 0.03456425,\n",
            " 'Loss/regularization_loss': 0.08800661,\n",
            " 'Loss/total_loss': 0.19228733,\n",
            " 'learning_rate': 0.0025999602}\n",
            "I1108 21:31:11.899127 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.06971646,\n",
            " 'Loss/localization_loss': 0.03456425,\n",
            " 'Loss/regularization_loss': 0.08800661,\n",
            " 'Loss/total_loss': 0.19228733,\n",
            " 'learning_rate': 0.0025999602}\n",
            "INFO:tensorflow:Step 900 per-step time 1.110s\n",
            "I1108 21:33:02.867910 138286988440000 model_lib_v2.py:705] Step 900 per-step time 1.110s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0603274,\n",
            " 'Loss/localization_loss': 0.03647031,\n",
            " 'Loss/regularization_loss': 0.08799266,\n",
            " 'Loss/total_loss': 0.18479037,\n",
            " 'learning_rate': 0.0027166302}\n",
            "I1108 21:33:02.868449 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.0603274,\n",
            " 'Loss/localization_loss': 0.03647031,\n",
            " 'Loss/regularization_loss': 0.08799266,\n",
            " 'Loss/total_loss': 0.18479037,\n",
            " 'learning_rate': 0.0027166302}\n",
            "INFO:tensorflow:Step 1000 per-step time 1.118s\n",
            "I1108 21:34:54.695014 138286988440000 model_lib_v2.py:705] Step 1000 per-step time 1.118s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06306918,\n",
            " 'Loss/localization_loss': 0.089391895,\n",
            " 'Loss/regularization_loss': 0.0879778,\n",
            " 'Loss/total_loss': 0.24043888,\n",
            " 'learning_rate': 0.0028333003}\n",
            "I1108 21:34:54.695434 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.06306918,\n",
            " 'Loss/localization_loss': 0.089391895,\n",
            " 'Loss/regularization_loss': 0.0879778,\n",
            " 'Loss/total_loss': 0.24043888,\n",
            " 'learning_rate': 0.0028333003}\n",
            "INFO:tensorflow:Step 1100 per-step time 1.092s\n",
            "I1108 21:36:43.881678 138286988440000 model_lib_v2.py:705] Step 1100 per-step time 1.092s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08137569,\n",
            " 'Loss/localization_loss': 0.045287106,\n",
            " 'Loss/regularization_loss': 0.08796317,\n",
            " 'Loss/total_loss': 0.21462595,\n",
            " 'learning_rate': 0.0029499703}\n",
            "I1108 21:36:43.882031 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.08137569,\n",
            " 'Loss/localization_loss': 0.045287106,\n",
            " 'Loss/regularization_loss': 0.08796317,\n",
            " 'Loss/total_loss': 0.21462595,\n",
            " 'learning_rate': 0.0029499703}\n",
            "INFO:tensorflow:Step 1200 per-step time 1.098s\n",
            "I1108 21:38:33.665557 138286988440000 model_lib_v2.py:705] Step 1200 per-step time 1.098s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05661999,\n",
            " 'Loss/localization_loss': 0.038257387,\n",
            " 'Loss/regularization_loss': 0.0879481,\n",
            " 'Loss/total_loss': 0.18282548,\n",
            " 'learning_rate': 0.0030666403}\n",
            "I1108 21:38:33.665929 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.05661999,\n",
            " 'Loss/localization_loss': 0.038257387,\n",
            " 'Loss/regularization_loss': 0.0879481,\n",
            " 'Loss/total_loss': 0.18282548,\n",
            " 'learning_rate': 0.0030666403}\n",
            "INFO:tensorflow:Step 1300 per-step time 1.080s\n",
            "I1108 21:40:21.658605 138286988440000 model_lib_v2.py:705] Step 1300 per-step time 1.080s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.066008344,\n",
            " 'Loss/localization_loss': 0.025324257,\n",
            " 'Loss/regularization_loss': 0.087930955,\n",
            " 'Loss/total_loss': 0.17926356,\n",
            " 'learning_rate': 0.0031833102}\n",
            "I1108 21:40:21.658980 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.066008344,\n",
            " 'Loss/localization_loss': 0.025324257,\n",
            " 'Loss/regularization_loss': 0.087930955,\n",
            " 'Loss/total_loss': 0.17926356,\n",
            " 'learning_rate': 0.0031833102}\n",
            "INFO:tensorflow:Step 1400 per-step time 1.102s\n",
            "I1108 21:42:11.813407 138286988440000 model_lib_v2.py:705] Step 1400 per-step time 1.102s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.066445835,\n",
            " 'Loss/localization_loss': 0.065105446,\n",
            " 'Loss/regularization_loss': 0.08791266,\n",
            " 'Loss/total_loss': 0.21946394,\n",
            " 'learning_rate': 0.0032999802}\n",
            "I1108 21:42:11.813862 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.066445835,\n",
            " 'Loss/localization_loss': 0.065105446,\n",
            " 'Loss/regularization_loss': 0.08791266,\n",
            " 'Loss/total_loss': 0.21946394,\n",
            " 'learning_rate': 0.0032999802}\n",
            "INFO:tensorflow:Step 1500 per-step time 1.087s\n",
            "I1108 21:44:00.505515 138286988440000 model_lib_v2.py:705] Step 1500 per-step time 1.087s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09151569,\n",
            " 'Loss/localization_loss': 0.035092,\n",
            " 'Loss/regularization_loss': 0.08789485,\n",
            " 'Loss/total_loss': 0.21450254,\n",
            " 'learning_rate': 0.0034166502}\n",
            "I1108 21:44:00.505858 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.09151569,\n",
            " 'Loss/localization_loss': 0.035092,\n",
            " 'Loss/regularization_loss': 0.08789485,\n",
            " 'Loss/total_loss': 0.21450254,\n",
            " 'learning_rate': 0.0034166502}\n",
            "INFO:tensorflow:Step 1600 per-step time 1.087s\n",
            "I1108 21:45:49.231282 138286988440000 model_lib_v2.py:705] Step 1600 per-step time 1.087s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.083613165,\n",
            " 'Loss/localization_loss': 0.027422726,\n",
            " 'Loss/regularization_loss': 0.08787628,\n",
            " 'Loss/total_loss': 0.19891217,\n",
            " 'learning_rate': 0.0035333203}\n",
            "I1108 21:45:49.231666 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.083613165,\n",
            " 'Loss/localization_loss': 0.027422726,\n",
            " 'Loss/regularization_loss': 0.08787628,\n",
            " 'Loss/total_loss': 0.19891217,\n",
            " 'learning_rate': 0.0035333203}\n",
            "INFO:tensorflow:Step 1700 per-step time 1.094s\n",
            "I1108 21:47:38.630660 138286988440000 model_lib_v2.py:705] Step 1700 per-step time 1.094s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.062353007,\n",
            " 'Loss/localization_loss': 0.020368181,\n",
            " 'Loss/regularization_loss': 0.08785729,\n",
            " 'Loss/total_loss': 0.17057848,\n",
            " 'learning_rate': 0.00364999}\n",
            "I1108 21:47:38.631075 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.062353007,\n",
            " 'Loss/localization_loss': 0.020368181,\n",
            " 'Loss/regularization_loss': 0.08785729,\n",
            " 'Loss/total_loss': 0.17057848,\n",
            " 'learning_rate': 0.00364999}\n",
            "INFO:tensorflow:Step 1800 per-step time 1.086s\n",
            "I1108 21:49:27.246908 138286988440000 model_lib_v2.py:705] Step 1800 per-step time 1.086s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07424736,\n",
            " 'Loss/localization_loss': 0.044759277,\n",
            " 'Loss/regularization_loss': 0.08783663,\n",
            " 'Loss/total_loss': 0.20684327,\n",
            " 'learning_rate': 0.00376666}\n",
            "I1108 21:49:27.247328 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.07424736,\n",
            " 'Loss/localization_loss': 0.044759277,\n",
            " 'Loss/regularization_loss': 0.08783663,\n",
            " 'Loss/total_loss': 0.20684327,\n",
            " 'learning_rate': 0.00376666}\n",
            "INFO:tensorflow:Step 1900 per-step time 1.113s\n",
            "I1108 21:51:18.531763 138286988440000 model_lib_v2.py:705] Step 1900 per-step time 1.113s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.105678976,\n",
            " 'Loss/localization_loss': 0.058483403,\n",
            " 'Loss/regularization_loss': 0.087814786,\n",
            " 'Loss/total_loss': 0.25197715,\n",
            " 'learning_rate': 0.0038833302}\n",
            "I1108 21:51:18.532159 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.105678976,\n",
            " 'Loss/localization_loss': 0.058483403,\n",
            " 'Loss/regularization_loss': 0.087814786,\n",
            " 'Loss/total_loss': 0.25197715,\n",
            " 'learning_rate': 0.0038833302}\n",
            "INFO:tensorflow:Step 2000 per-step time 1.081s\n",
            "I1108 21:53:06.643788 138286988440000 model_lib_v2.py:705] Step 2000 per-step time 1.081s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.059058804,\n",
            " 'Loss/localization_loss': 0.018204309,\n",
            " 'Loss/regularization_loss': 0.08779392,\n",
            " 'Loss/total_loss': 0.16505703,\n",
            " 'learning_rate': 0.004}\n",
            "I1108 21:53:06.644149 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.059058804,\n",
            " 'Loss/localization_loss': 0.018204309,\n",
            " 'Loss/regularization_loss': 0.08779392,\n",
            " 'Loss/total_loss': 0.16505703,\n",
            " 'learning_rate': 0.004}\n",
            "INFO:tensorflow:Step 2100 per-step time 1.089s\n",
            "I1108 21:54:55.571198 138286988440000 model_lib_v2.py:705] Step 2100 per-step time 1.089s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06004662,\n",
            " 'Loss/localization_loss': 0.024787331,\n",
            " 'Loss/regularization_loss': 0.087770626,\n",
            " 'Loss/total_loss': 0.17260458,\n",
            " 'learning_rate': 0.0039999573}\n",
            "I1108 21:54:55.571630 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.06004662,\n",
            " 'Loss/localization_loss': 0.024787331,\n",
            " 'Loss/regularization_loss': 0.087770626,\n",
            " 'Loss/total_loss': 0.17260458,\n",
            " 'learning_rate': 0.0039999573}\n",
            "INFO:tensorflow:Step 2200 per-step time 1.099s\n",
            "I1108 21:56:45.462518 138286988440000 model_lib_v2.py:705] Step 2200 per-step time 1.099s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11457686,\n",
            " 'Loss/localization_loss': 0.075941384,\n",
            " 'Loss/regularization_loss': 0.08774743,\n",
            " 'Loss/total_loss': 0.27826566,\n",
            " 'learning_rate': 0.003999829}\n",
            "I1108 21:56:45.462931 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.11457686,\n",
            " 'Loss/localization_loss': 0.075941384,\n",
            " 'Loss/regularization_loss': 0.08774743,\n",
            " 'Loss/total_loss': 0.27826566,\n",
            " 'learning_rate': 0.003999829}\n",
            "INFO:tensorflow:Step 2300 per-step time 1.113s\n",
            "I1108 21:58:36.735703 138286988440000 model_lib_v2.py:705] Step 2300 per-step time 1.113s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.081197485,\n",
            " 'Loss/localization_loss': 0.04190887,\n",
            " 'Loss/regularization_loss': 0.08772405,\n",
            " 'Loss/total_loss': 0.21083042,\n",
            " 'learning_rate': 0.0039996146}\n",
            "I1108 21:58:36.736213 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.081197485,\n",
            " 'Loss/localization_loss': 0.04190887,\n",
            " 'Loss/regularization_loss': 0.08772405,\n",
            " 'Loss/total_loss': 0.21083042,\n",
            " 'learning_rate': 0.0039996146}\n",
            "INFO:tensorflow:Step 2400 per-step time 1.098s\n",
            "I1108 22:00:26.499220 138286988440000 model_lib_v2.py:705] Step 2400 per-step time 1.098s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07435685,\n",
            " 'Loss/localization_loss': 0.024295086,\n",
            " 'Loss/regularization_loss': 0.087701365,\n",
            " 'Loss/total_loss': 0.1863533,\n",
            " 'learning_rate': 0.003999315}\n",
            "I1108 22:00:26.499581 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.07435685,\n",
            " 'Loss/localization_loss': 0.024295086,\n",
            " 'Loss/regularization_loss': 0.087701365,\n",
            " 'Loss/total_loss': 0.1863533,\n",
            " 'learning_rate': 0.003999315}\n",
            "INFO:tensorflow:Step 2500 per-step time 1.093s\n",
            "I1108 22:02:15.838093 138286988440000 model_lib_v2.py:705] Step 2500 per-step time 1.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12115395,\n",
            " 'Loss/localization_loss': 0.070388176,\n",
            " 'Loss/regularization_loss': 0.08767738,\n",
            " 'Loss/total_loss': 0.2792195,\n",
            " 'learning_rate': 0.003998929}\n",
            "I1108 22:02:15.838454 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.12115395,\n",
            " 'Loss/localization_loss': 0.070388176,\n",
            " 'Loss/regularization_loss': 0.08767738,\n",
            " 'Loss/total_loss': 0.2792195,\n",
            " 'learning_rate': 0.003998929}\n",
            "INFO:tensorflow:Step 2600 per-step time 1.082s\n",
            "I1108 22:04:04.079701 138286988440000 model_lib_v2.py:705] Step 2600 per-step time 1.082s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04664385,\n",
            " 'Loss/localization_loss': 0.012481106,\n",
            " 'Loss/regularization_loss': 0.08765489,\n",
            " 'Loss/total_loss': 0.14677985,\n",
            " 'learning_rate': 0.003998458}\n",
            "I1108 22:04:04.080051 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.04664385,\n",
            " 'Loss/localization_loss': 0.012481106,\n",
            " 'Loss/regularization_loss': 0.08765489,\n",
            " 'Loss/total_loss': 0.14677985,\n",
            " 'learning_rate': 0.003998458}\n",
            "INFO:tensorflow:Step 2700 per-step time 1.085s\n",
            "I1108 22:05:52.558829 138286988440000 model_lib_v2.py:705] Step 2700 per-step time 1.085s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09370173,\n",
            " 'Loss/localization_loss': 0.0136607615,\n",
            " 'Loss/regularization_loss': 0.08763138,\n",
            " 'Loss/total_loss': 0.19499387,\n",
            " 'learning_rate': 0.0039979015}\n",
            "I1108 22:05:52.559237 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.09370173,\n",
            " 'Loss/localization_loss': 0.0136607615,\n",
            " 'Loss/regularization_loss': 0.08763138,\n",
            " 'Loss/total_loss': 0.19499387,\n",
            " 'learning_rate': 0.0039979015}\n",
            "INFO:tensorflow:Step 2800 per-step time 1.055s\n",
            "I1108 22:07:38.047659 138286988440000 model_lib_v2.py:705] Step 2800 per-step time 1.055s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.035727113,\n",
            " 'Loss/localization_loss': 0.008209854,\n",
            " 'Loss/regularization_loss': 0.08760735,\n",
            " 'Loss/total_loss': 0.13154432,\n",
            " 'learning_rate': 0.0039972593}\n",
            "I1108 22:07:38.048059 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.035727113,\n",
            " 'Loss/localization_loss': 0.008209854,\n",
            " 'Loss/regularization_loss': 0.08760735,\n",
            " 'Loss/total_loss': 0.13154432,\n",
            " 'learning_rate': 0.0039972593}\n",
            "INFO:tensorflow:Step 2900 per-step time 1.067s\n",
            "I1108 22:09:24.741653 138286988440000 model_lib_v2.py:705] Step 2900 per-step time 1.067s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05443086,\n",
            " 'Loss/localization_loss': 0.023818852,\n",
            " 'Loss/regularization_loss': 0.08758374,\n",
            " 'Loss/total_loss': 0.16583346,\n",
            " 'learning_rate': 0.0039965315}\n",
            "I1108 22:09:24.742015 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.05443086,\n",
            " 'Loss/localization_loss': 0.023818852,\n",
            " 'Loss/regularization_loss': 0.08758374,\n",
            " 'Loss/total_loss': 0.16583346,\n",
            " 'learning_rate': 0.0039965315}\n",
            "INFO:tensorflow:Step 3000 per-step time 1.093s\n",
            "I1108 22:11:14.015963 138286988440000 model_lib_v2.py:705] Step 3000 per-step time 1.093s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05748795,\n",
            " 'Loss/localization_loss': 0.016292674,\n",
            " 'Loss/regularization_loss': 0.08756039,\n",
            " 'Loss/total_loss': 0.16134101,\n",
            " 'learning_rate': 0.003995718}\n",
            "I1108 22:11:14.016340 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.05748795,\n",
            " 'Loss/localization_loss': 0.016292674,\n",
            " 'Loss/regularization_loss': 0.08756039,\n",
            " 'Loss/total_loss': 0.16134101,\n",
            " 'learning_rate': 0.003995718}\n",
            "INFO:tensorflow:Step 3100 per-step time 1.078s\n",
            "I1108 22:13:01.810955 138286988440000 model_lib_v2.py:705] Step 3100 per-step time 1.078s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04211518,\n",
            " 'Loss/localization_loss': 0.0137312645,\n",
            " 'Loss/regularization_loss': 0.08753668,\n",
            " 'Loss/total_loss': 0.14338313,\n",
            " 'learning_rate': 0.0039948192}\n",
            "I1108 22:13:01.811354 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.04211518,\n",
            " 'Loss/localization_loss': 0.0137312645,\n",
            " 'Loss/regularization_loss': 0.08753668,\n",
            " 'Loss/total_loss': 0.14338313,\n",
            " 'learning_rate': 0.0039948192}\n",
            "INFO:tensorflow:Step 3200 per-step time 1.081s\n",
            "I1108 22:14:49.898863 138286988440000 model_lib_v2.py:705] Step 3200 per-step time 1.081s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.060068727,\n",
            " 'Loss/localization_loss': 0.032065663,\n",
            " 'Loss/regularization_loss': 0.087512456,\n",
            " 'Loss/total_loss': 0.17964685,\n",
            " 'learning_rate': 0.003993835}\n",
            "I1108 22:14:49.899236 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.060068727,\n",
            " 'Loss/localization_loss': 0.032065663,\n",
            " 'Loss/regularization_loss': 0.087512456,\n",
            " 'Loss/total_loss': 0.17964685,\n",
            " 'learning_rate': 0.003993835}\n",
            "INFO:tensorflow:Step 3300 per-step time 1.076s\n",
            "I1108 22:16:37.522736 138286988440000 model_lib_v2.py:705] Step 3300 per-step time 1.076s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.05448442,\n",
            " 'Loss/localization_loss': 0.009272712,\n",
            " 'Loss/regularization_loss': 0.087489545,\n",
            " 'Loss/total_loss': 0.15124668,\n",
            " 'learning_rate': 0.003992765}\n",
            "I1108 22:16:37.523074 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.05448442,\n",
            " 'Loss/localization_loss': 0.009272712,\n",
            " 'Loss/regularization_loss': 0.087489545,\n",
            " 'Loss/total_loss': 0.15124668,\n",
            " 'learning_rate': 0.003992765}\n",
            "INFO:tensorflow:Step 3400 per-step time 1.090s\n",
            "I1108 22:18:26.476189 138286988440000 model_lib_v2.py:705] Step 3400 per-step time 1.090s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.053923942,\n",
            " 'Loss/localization_loss': 0.012870314,\n",
            " 'Loss/regularization_loss': 0.08746563,\n",
            " 'Loss/total_loss': 0.15425989,\n",
            " 'learning_rate': 0.00399161}\n",
            "I1108 22:18:26.476626 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.053923942,\n",
            " 'Loss/localization_loss': 0.012870314,\n",
            " 'Loss/regularization_loss': 0.08746563,\n",
            " 'Loss/total_loss': 0.15425989,\n",
            " 'learning_rate': 0.00399161}\n",
            "INFO:tensorflow:Step 3500 per-step time 1.074s\n",
            "I1108 22:20:13.922066 138286988440000 model_lib_v2.py:705] Step 3500 per-step time 1.074s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.047969755,\n",
            " 'Loss/localization_loss': 0.021349512,\n",
            " 'Loss/regularization_loss': 0.087441735,\n",
            " 'Loss/total_loss': 0.15676099,\n",
            " 'learning_rate': 0.0039903694}\n",
            "I1108 22:20:13.922536 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.047969755,\n",
            " 'Loss/localization_loss': 0.021349512,\n",
            " 'Loss/regularization_loss': 0.087441735,\n",
            " 'Loss/total_loss': 0.15676099,\n",
            " 'learning_rate': 0.0039903694}\n",
            "INFO:tensorflow:Step 3600 per-step time 1.101s\n",
            "I1108 22:22:04.041637 138286988440000 model_lib_v2.py:705] Step 3600 per-step time 1.101s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.035358425,\n",
            " 'Loss/localization_loss': 0.012768528,\n",
            " 'Loss/regularization_loss': 0.087417684,\n",
            " 'Loss/total_loss': 0.13554464,\n",
            " 'learning_rate': 0.003989044}\n",
            "I1108 22:22:04.041989 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.035358425,\n",
            " 'Loss/localization_loss': 0.012768528,\n",
            " 'Loss/regularization_loss': 0.087417684,\n",
            " 'Loss/total_loss': 0.13554464,\n",
            " 'learning_rate': 0.003989044}\n",
            "INFO:tensorflow:Step 3700 per-step time 1.076s\n",
            "I1108 22:23:51.634470 138286988440000 model_lib_v2.py:705] Step 3700 per-step time 1.076s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07483095,\n",
            " 'Loss/localization_loss': 0.022493036,\n",
            " 'Loss/regularization_loss': 0.08739419,\n",
            " 'Loss/total_loss': 0.18471818,\n",
            " 'learning_rate': 0.003987633}\n",
            "I1108 22:23:51.635027 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.07483095,\n",
            " 'Loss/localization_loss': 0.022493036,\n",
            " 'Loss/regularization_loss': 0.08739419,\n",
            " 'Loss/total_loss': 0.18471818,\n",
            " 'learning_rate': 0.003987633}\n",
            "INFO:tensorflow:Step 3800 per-step time 1.074s\n",
            "I1108 22:25:39.048340 138286988440000 model_lib_v2.py:705] Step 3800 per-step time 1.074s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.051978633,\n",
            " 'Loss/localization_loss': 0.015550166,\n",
            " 'Loss/regularization_loss': 0.08737079,\n",
            " 'Loss/total_loss': 0.1548996,\n",
            " 'learning_rate': 0.003986137}\n",
            "I1108 22:25:39.048726 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.051978633,\n",
            " 'Loss/localization_loss': 0.015550166,\n",
            " 'Loss/regularization_loss': 0.08737079,\n",
            " 'Loss/total_loss': 0.1548996,\n",
            " 'learning_rate': 0.003986137}\n",
            "INFO:tensorflow:Step 3900 per-step time 1.081s\n",
            "I1108 22:27:27.190583 138286988440000 model_lib_v2.py:705] Step 3900 per-step time 1.081s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07560175,\n",
            " 'Loss/localization_loss': 0.01831856,\n",
            " 'Loss/regularization_loss': 0.08734641,\n",
            " 'Loss/total_loss': 0.18126673,\n",
            " 'learning_rate': 0.003984556}\n",
            "I1108 22:27:27.190943 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.07560175,\n",
            " 'Loss/localization_loss': 0.01831856,\n",
            " 'Loss/regularization_loss': 0.08734641,\n",
            " 'Loss/total_loss': 0.18126673,\n",
            " 'learning_rate': 0.003984556}\n",
            "INFO:tensorflow:Step 4000 per-step time 1.065s\n",
            "I1108 22:29:13.662063 138286988440000 model_lib_v2.py:705] Step 4000 per-step time 1.065s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06220149,\n",
            " 'Loss/localization_loss': 0.0364824,\n",
            " 'Loss/regularization_loss': 0.08732243,\n",
            " 'Loss/total_loss': 0.18600632,\n",
            " 'learning_rate': 0.00398289}\n",
            "I1108 22:29:13.662463 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.06220149,\n",
            " 'Loss/localization_loss': 0.0364824,\n",
            " 'Loss/regularization_loss': 0.08732243,\n",
            " 'Loss/total_loss': 0.18600632,\n",
            " 'learning_rate': 0.00398289}\n",
            "INFO:tensorflow:Step 4100 per-step time 1.070s\n",
            "I1108 22:31:00.706153 138286988440000 model_lib_v2.py:705] Step 4100 per-step time 1.070s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0460177,\n",
            " 'Loss/localization_loss': 0.013331927,\n",
            " 'Loss/regularization_loss': 0.087298386,\n",
            " 'Loss/total_loss': 0.14664802,\n",
            " 'learning_rate': 0.003981139}\n",
            "I1108 22:31:00.706541 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.0460177,\n",
            " 'Loss/localization_loss': 0.013331927,\n",
            " 'Loss/regularization_loss': 0.087298386,\n",
            " 'Loss/total_loss': 0.14664802,\n",
            " 'learning_rate': 0.003981139}\n",
            "INFO:tensorflow:Step 4200 per-step time 1.084s\n",
            "I1108 22:32:49.106243 138286988440000 model_lib_v2.py:705] Step 4200 per-step time 1.084s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04999074,\n",
            " 'Loss/localization_loss': 0.016629012,\n",
            " 'Loss/regularization_loss': 0.08727457,\n",
            " 'Loss/total_loss': 0.15389432,\n",
            " 'learning_rate': 0.003979303}\n",
            "I1108 22:32:49.106683 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.04999074,\n",
            " 'Loss/localization_loss': 0.016629012,\n",
            " 'Loss/regularization_loss': 0.08727457,\n",
            " 'Loss/total_loss': 0.15389432,\n",
            " 'learning_rate': 0.003979303}\n",
            "INFO:tensorflow:Step 4300 per-step time 1.077s\n",
            "I1108 22:34:36.819802 138286988440000 model_lib_v2.py:705] Step 4300 per-step time 1.077s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.052656095,\n",
            " 'Loss/localization_loss': 0.01588029,\n",
            " 'Loss/regularization_loss': 0.08725112,\n",
            " 'Loss/total_loss': 0.15578751,\n",
            " 'learning_rate': 0.0039773826}\n",
            "I1108 22:34:36.820147 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.052656095,\n",
            " 'Loss/localization_loss': 0.01588029,\n",
            " 'Loss/regularization_loss': 0.08725112,\n",
            " 'Loss/total_loss': 0.15578751,\n",
            " 'learning_rate': 0.0039773826}\n",
            "INFO:tensorflow:Step 4400 per-step time 1.067s\n",
            "I1108 22:36:23.533461 138286988440000 model_lib_v2.py:705] Step 4400 per-step time 1.067s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03846856,\n",
            " 'Loss/localization_loss': 0.019691775,\n",
            " 'Loss/regularization_loss': 0.08722611,\n",
            " 'Loss/total_loss': 0.14538644,\n",
            " 'learning_rate': 0.003975377}\n",
            "I1108 22:36:23.533805 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.03846856,\n",
            " 'Loss/localization_loss': 0.019691775,\n",
            " 'Loss/regularization_loss': 0.08722611,\n",
            " 'Loss/total_loss': 0.14538644,\n",
            " 'learning_rate': 0.003975377}\n",
            "INFO:tensorflow:Step 4500 per-step time 1.090s\n",
            "I1108 22:38:12.496424 138286988440000 model_lib_v2.py:705] Step 4500 per-step time 1.090s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04924642,\n",
            " 'Loss/localization_loss': 0.01603887,\n",
            " 'Loss/regularization_loss': 0.08720272,\n",
            " 'Loss/total_loss': 0.15248801,\n",
            " 'learning_rate': 0.0039732866}\n",
            "I1108 22:38:12.496854 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.04924642,\n",
            " 'Loss/localization_loss': 0.01603887,\n",
            " 'Loss/regularization_loss': 0.08720272,\n",
            " 'Loss/total_loss': 0.15248801,\n",
            " 'learning_rate': 0.0039732866}\n",
            "INFO:tensorflow:Step 4600 per-step time 1.076s\n",
            "I1108 22:40:00.118025 138286988440000 model_lib_v2.py:705] Step 4600 per-step time 1.076s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07309511,\n",
            " 'Loss/localization_loss': 0.031103613,\n",
            " 'Loss/regularization_loss': 0.08717943,\n",
            " 'Loss/total_loss': 0.19137815,\n",
            " 'learning_rate': 0.0039711124}\n",
            "I1108 22:40:00.118410 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.07309511,\n",
            " 'Loss/localization_loss': 0.031103613,\n",
            " 'Loss/regularization_loss': 0.08717943,\n",
            " 'Loss/total_loss': 0.19137815,\n",
            " 'learning_rate': 0.0039711124}\n",
            "INFO:tensorflow:Step 4700 per-step time 1.063s\n",
            "I1108 22:41:46.466540 138286988440000 model_lib_v2.py:705] Step 4700 per-step time 1.063s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03250177,\n",
            " 'Loss/localization_loss': 0.009626333,\n",
            " 'Loss/regularization_loss': 0.08715579,\n",
            " 'Loss/total_loss': 0.12928389,\n",
            " 'learning_rate': 0.003968853}\n",
            "I1108 22:41:46.466882 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.03250177,\n",
            " 'Loss/localization_loss': 0.009626333,\n",
            " 'Loss/regularization_loss': 0.08715579,\n",
            " 'Loss/total_loss': 0.12928389,\n",
            " 'learning_rate': 0.003968853}\n",
            "INFO:tensorflow:Step 4800 per-step time 1.063s\n",
            "I1108 22:43:32.727631 138286988440000 model_lib_v2.py:705] Step 4800 per-step time 1.063s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.078810945,\n",
            " 'Loss/localization_loss': 0.012706759,\n",
            " 'Loss/regularization_loss': 0.0871323,\n",
            " 'Loss/total_loss': 0.17864999,\n",
            " 'learning_rate': 0.00396651}\n",
            "I1108 22:43:32.727984 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.078810945,\n",
            " 'Loss/localization_loss': 0.012706759,\n",
            " 'Loss/regularization_loss': 0.0871323,\n",
            " 'Loss/total_loss': 0.17864999,\n",
            " 'learning_rate': 0.00396651}\n",
            "INFO:tensorflow:Step 4900 per-step time 1.062s\n",
            "I1108 22:45:18.965538 138286988440000 model_lib_v2.py:705] Step 4900 per-step time 1.062s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06531858,\n",
            " 'Loss/localization_loss': 0.0198019,\n",
            " 'Loss/regularization_loss': 0.08710764,\n",
            " 'Loss/total_loss': 0.17222811,\n",
            " 'learning_rate': 0.0039640823}\n",
            "I1108 22:45:18.965939 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.06531858,\n",
            " 'Loss/localization_loss': 0.0198019,\n",
            " 'Loss/regularization_loss': 0.08710764,\n",
            " 'Loss/total_loss': 0.17222811,\n",
            " 'learning_rate': 0.0039640823}\n",
            "INFO:tensorflow:Step 5000 per-step time 1.063s\n",
            "I1108 22:47:05.299731 138286988440000 model_lib_v2.py:705] Step 5000 per-step time 1.063s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.03595286,\n",
            " 'Loss/localization_loss': 0.012833687,\n",
            " 'Loss/regularization_loss': 0.087083764,\n",
            " 'Loss/total_loss': 0.13587031,\n",
            " 'learning_rate': 0.0039615706}\n",
            "I1108 22:47:05.300142 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.03595286,\n",
            " 'Loss/localization_loss': 0.012833687,\n",
            " 'Loss/regularization_loss': 0.087083764,\n",
            " 'Loss/total_loss': 0.13587031,\n",
            " 'learning_rate': 0.0039615706}\n",
            "INFO:tensorflow:Step 5100 per-step time 1.081s\n",
            "I1108 22:48:53.416355 138286988440000 model_lib_v2.py:705] Step 5100 per-step time 1.081s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.052458286,\n",
            " 'Loss/localization_loss': 0.02277855,\n",
            " 'Loss/regularization_loss': 0.08705981,\n",
            " 'Loss/total_loss': 0.16229665,\n",
            " 'learning_rate': 0.003958975}\n",
            "I1108 22:48:53.416736 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.052458286,\n",
            " 'Loss/localization_loss': 0.02277855,\n",
            " 'Loss/regularization_loss': 0.08705981,\n",
            " 'Loss/total_loss': 0.16229665,\n",
            " 'learning_rate': 0.003958975}\n",
            "INFO:tensorflow:Step 5200 per-step time 1.092s\n",
            "I1108 22:50:42.569815 138286988440000 model_lib_v2.py:705] Step 5200 per-step time 1.092s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.06445571,\n",
            " 'Loss/localization_loss': 0.015638052,\n",
            " 'Loss/regularization_loss': 0.087036,\n",
            " 'Loss/total_loss': 0.16712976,\n",
            " 'learning_rate': 0.0039562955}\n",
            "I1108 22:50:42.570149 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.06445571,\n",
            " 'Loss/localization_loss': 0.015638052,\n",
            " 'Loss/regularization_loss': 0.087036,\n",
            " 'Loss/total_loss': 0.16712976,\n",
            " 'learning_rate': 0.0039562955}\n",
            "INFO:tensorflow:Step 5300 per-step time 1.071s\n",
            "I1108 22:52:29.689117 138286988440000 model_lib_v2.py:705] Step 5300 per-step time 1.071s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.046804138,\n",
            " 'Loss/localization_loss': 0.008018887,\n",
            " 'Loss/regularization_loss': 0.08701207,\n",
            " 'Loss/total_loss': 0.1418351,\n",
            " 'learning_rate': 0.003953532}\n",
            "I1108 22:52:29.689523 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.046804138,\n",
            " 'Loss/localization_loss': 0.008018887,\n",
            " 'Loss/regularization_loss': 0.08701207,\n",
            " 'Loss/total_loss': 0.1418351,\n",
            " 'learning_rate': 0.003953532}\n",
            "INFO:tensorflow:Step 5400 per-step time 1.053s\n",
            "I1108 22:54:14.960253 138286988440000 model_lib_v2.py:705] Step 5400 per-step time 1.053s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.044782903,\n",
            " 'Loss/localization_loss': 0.026495209,\n",
            " 'Loss/regularization_loss': 0.08698809,\n",
            " 'Loss/total_loss': 0.1582662,\n",
            " 'learning_rate': 0.003950685}\n",
            "I1108 22:54:14.960622 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.044782903,\n",
            " 'Loss/localization_loss': 0.026495209,\n",
            " 'Loss/regularization_loss': 0.08698809,\n",
            " 'Loss/total_loss': 0.1582662,\n",
            " 'learning_rate': 0.003950685}\n",
            "INFO:tensorflow:Step 5500 per-step time 1.072s\n",
            "I1108 22:56:02.187266 138286988440000 model_lib_v2.py:705] Step 5500 per-step time 1.072s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.090840325,\n",
            " 'Loss/localization_loss': 0.075998016,\n",
            " 'Loss/regularization_loss': 0.08696374,\n",
            " 'Loss/total_loss': 0.2538021,\n",
            " 'learning_rate': 0.003947754}\n",
            "I1108 22:56:02.187656 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.090840325,\n",
            " 'Loss/localization_loss': 0.075998016,\n",
            " 'Loss/regularization_loss': 0.08696374,\n",
            " 'Loss/total_loss': 0.2538021,\n",
            " 'learning_rate': 0.003947754}\n",
            "INFO:tensorflow:Step 5600 per-step time 1.086s\n",
            "I1108 22:57:50.766422 138286988440000 model_lib_v2.py:705] Step 5600 per-step time 1.086s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04037064,\n",
            " 'Loss/localization_loss': 0.008807855,\n",
            " 'Loss/regularization_loss': 0.08693977,\n",
            " 'Loss/total_loss': 0.13611826,\n",
            " 'learning_rate': 0.00394474}\n",
            "I1108 22:57:50.766745 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.04037064,\n",
            " 'Loss/localization_loss': 0.008807855,\n",
            " 'Loss/regularization_loss': 0.08693977,\n",
            " 'Loss/total_loss': 0.13611826,\n",
            " 'learning_rate': 0.00394474}\n",
            "INFO:tensorflow:Step 5700 per-step time 1.062s\n",
            "I1108 22:59:37.004120 138286988440000 model_lib_v2.py:705] Step 5700 per-step time 1.062s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.036605466,\n",
            " 'Loss/localization_loss': 0.008048841,\n",
            " 'Loss/regularization_loss': 0.086915895,\n",
            " 'Loss/total_loss': 0.1315702,\n",
            " 'learning_rate': 0.0039416426}\n",
            "I1108 22:59:37.004497 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.036605466,\n",
            " 'Loss/localization_loss': 0.008048841,\n",
            " 'Loss/regularization_loss': 0.086915895,\n",
            " 'Loss/total_loss': 0.1315702,\n",
            " 'learning_rate': 0.0039416426}\n",
            "INFO:tensorflow:Step 5800 per-step time 1.088s\n",
            "I1108 23:01:25.802352 138286988440000 model_lib_v2.py:705] Step 5800 per-step time 1.088s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.04292062,\n",
            " 'Loss/localization_loss': 0.017929507,\n",
            " 'Loss/regularization_loss': 0.08689216,\n",
            " 'Loss/total_loss': 0.14774229,\n",
            " 'learning_rate': 0.003938462}\n",
            "I1108 23:01:25.802775 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.04292062,\n",
            " 'Loss/localization_loss': 0.017929507,\n",
            " 'Loss/regularization_loss': 0.08689216,\n",
            " 'Loss/total_loss': 0.14774229,\n",
            " 'learning_rate': 0.003938462}\n",
            "INFO:tensorflow:Step 5900 per-step time 1.074s\n",
            "I1108 23:03:13.187437 138286988440000 model_lib_v2.py:705] Step 5900 per-step time 1.074s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.045991372,\n",
            " 'Loss/localization_loss': 0.014934293,\n",
            " 'Loss/regularization_loss': 0.08686808,\n",
            " 'Loss/total_loss': 0.14779374,\n",
            " 'learning_rate': 0.0039351983}\n",
            "I1108 23:03:13.187801 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.045991372,\n",
            " 'Loss/localization_loss': 0.014934293,\n",
            " 'Loss/regularization_loss': 0.08686808,\n",
            " 'Loss/total_loss': 0.14779374,\n",
            " 'learning_rate': 0.0039351983}\n",
            "INFO:tensorflow:Step 6000 per-step time 1.070s\n",
            "I1108 23:05:00.151885 138286988440000 model_lib_v2.py:705] Step 6000 per-step time 1.070s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.045309175,\n",
            " 'Loss/localization_loss': 0.013177405,\n",
            " 'Loss/regularization_loss': 0.08684455,\n",
            " 'Loss/total_loss': 0.14533113,\n",
            " 'learning_rate': 0.0039318516}\n",
            "I1108 23:05:00.152276 138286988440000 model_lib_v2.py:708] {'Loss/classification_loss': 0.045309175,\n",
            " 'Loss/localization_loss': 0.013177405,\n",
            " 'Loss/regularization_loss': 0.08684455,\n",
            " 'Loss/total_loss': 0.14533113,\n",
            " 'learning_rate': 0.0039318516}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-bfba6dc9383a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm -rf {HOMEFOLDER}training_progress'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Run training!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'python {HOMEFOLDER}models/research/object_detection/model_main_tf2.py      --pipeline_config_path={pipeline_file}      --model_dir={model_dir}      --alsologtostderr      --checkpoint_every_n={checkpoint_every}      --num_train_steps={num_steps}      --num_workers=2      --sample_1_of_n_eval_examples=1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    455\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    202\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_monitor_process\u001b[0;34m(parent_pty, epoll, p, cmd, update_stdin_widget)\u001b[0m\n\u001b[1;32m    232\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_poll_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_poll_process\u001b[0;34m(parent_pty, epoll, p, cmd, decoder, state)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;31m# TODO(b/115527726): Rather than sleep, poll for incoming messages from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;31m# the frontend in the same poll as for the output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!rm -rf {HOMEFOLDER}training_progress\n",
        "# Run training!\n",
        "!python {HOMEFOLDER}models/research/object_detection/model_main_tf2.py \\\n",
        "    --pipeline_config_path={pipeline_file} \\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\\n",
        "    --checkpoint_every_n={checkpoint_every} \\\n",
        "    --num_train_steps={num_steps} \\\n",
        "    --num_workers=2 \\\n",
        "    --sample_1_of_n_eval_examples=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHxbX4ZpzXIv"
      },
      "source": [
        "Feel free to stop training early. Check the 'training_progress' folder to see all training checkpoints.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPg8oMnQDYKl"
      },
      "source": [
        "# 5.&nbsp;Convert Model to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaUU8tBlHifd"
      },
      "outputs": [],
      "source": [
        "#remove final output folder if it exists\n",
        "if os.path.exists(FINALOUTPUTFOLDER) and os.path.isdir(FINALOUTPUTFOLDER):\n",
        "  shutil.rmtree(FINALOUTPUTFOLDER)\n",
        "\n",
        "# Make a directory to store the trained TFLite model\n",
        "!mkdir {FINALOUTPUTFOLDER}\n",
        "print(FINALOUTPUTFOLDER)\n",
        "# Export graph\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = HOMEFOLDER+'training_progress'\n",
        "exporter_path = HOMEFOLDER+'models/research/object_detection/export_tflite_graph_tf2.py'\n",
        "output_directory = FINALOUTPUTFOLDER\n",
        "\n",
        "!python $exporter_path \\\n",
        "    --trained_checkpoint_dir $last_model_path \\\n",
        "    --output_directory $output_directory \\\n",
        "    --pipeline_config_path $pipeline_file\n",
        "\n",
        "# Convert to .tflite Flatbuffer\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "model_path_32bit = FINALOUTPUTFOLDER+'/limelight_neural_detector_32bit.tflite'\n",
        "with open(model_path_32bit, 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}\n",
        "!cp {HOMEFOLDER}models/mymodel/pipeline_file.config {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqahbHU1suBi"
      },
      "outputs": [],
      "source": [
        "# Export graph\n",
        "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
        "last_model_path = HOMEFOLDER+'training_progress'\n",
        "exporter_path = HOMEFOLDER+'models/research/object_detection/export_tflite_graph_tf2.py'\n",
        "output_directory = FINALOUTPUTFOLDER\n",
        "\n",
        "!python $exporter_path \\\n",
        "    --trained_checkpoint_dir $last_model_path \\\n",
        "    --output_directory $output_directory \\\n",
        "    --pipeline_config_path $pipeline_file\n",
        "\n",
        "# Convert to .tflite Flatbuffer\n",
        "import tensorflow as tf\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "tflite_model = converter.convert()\n",
        "model_path_32bit = FINALOUTPUTFOLDER+'/limelight_neural_detector_32bit.tflite'\n",
        "with open(model_path_32bit, 'wb') as f:\n",
        "  f.write(tflite_model)\n",
        "\n",
        "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTyqlXFTJ0Uv"
      },
      "source": [
        "# 6. Quantize model\n",
        "The \"TFLiteConverter\" module will perform [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) on the model. To quantize the model, we need to provide a set of example images. We will extract 100 images from the training tfrecord and place said images into the \"extracted_samples\" folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSNZtfj_k3NP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "def extract_images_from_tfrecord(tfrecord_path, output_folder, num_samples=100):\n",
        "    # Make sure the output directory exists\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Initialize a counter for the number of images saved\n",
        "    saved_images = 0\n",
        "\n",
        "    # Read the TFRecord file\n",
        "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
        "    for raw_record in raw_dataset.take(num_samples):\n",
        "        example = tf.train.Example()\n",
        "        example.ParseFromString(raw_record.numpy())\n",
        "\n",
        "        # Extract the image data (change 'image/encoded' if necessary)\n",
        "        image_data = example.features.feature['image/encoded'].bytes_list.value[0]\n",
        "\n",
        "        # Decode the image data and save as a file\n",
        "        image = Image.open(io.BytesIO(image_data))\n",
        "        image.save(os.path.join(output_folder, f'image_{saved_images}.png'))\n",
        "\n",
        "        saved_images += 1\n",
        "        if saved_images >= num_samples:\n",
        "            break\n",
        "\n",
        "    print(f\"Extracted {saved_images} images to {output_folder}\")\n",
        "\n",
        "# Set the path to your TFRecord file and the output directory\n",
        "tfrecord_path = train_record_fname\n",
        "extracted_sample_folder = HOMEFOLDER+'extracted_samples'\n",
        "\n",
        "#remove sample folder if it exists\n",
        "if os.path.exists(extracted_sample_folder) and os.path.isdir(extracted_sample_folder):\n",
        "  shutil.rmtree(extracted_sample_folder)\n",
        "\n",
        "# Extract images\n",
        "extract_images_from_tfrecord(tfrecord_path, extracted_sample_folder)\n",
        "\n",
        "\n",
        "# Get list of all images in train directory\n",
        "from google.cloud import storage\n",
        "import glob\n",
        "\n",
        "quant_image_list=[]\n",
        "if(MLENVIRONMENT==\"COLAB\"):\n",
        "\n",
        "    jpg_file_list = glob.glob(extracted_sample_folder + '/*.jpg')\n",
        "    jpeg_file_list = glob.glob(extracted_sample_folder + '/*.jpeg')\n",
        "    JPG_file_list = glob.glob(extracted_sample_folder + '/*.JPG')\n",
        "    png_file_list = glob.glob(extracted_sample_folder + '/*.png')\n",
        "    bmp_file_list = glob.glob(extracted_sample_folder + '/*.bmp')\n",
        "    quant_image_list = jpg_file_list + JPG_file_list + png_file_list + bmp_file_list\n",
        "\n",
        "print(\"pulling samples from \" + extracted_sample_folder)\n",
        "print(\"samples: \" + str(len(quant_image_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORzx0XRErSLV"
      },
      "outputs": [],
      "source": [
        "# A generator that provides a representative dataset\n",
        "# Code modified from https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb\n",
        "\n",
        "# First, get input details for model so we know how to preprocess images\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path_32bit)\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "height = input_details[0]['shape'][1]\n",
        "width = input_details[0]['shape'][2]\n",
        "\n",
        "import random\n",
        "\n",
        "def representative_data_gen():\n",
        "  dataset_list = quant_image_list\n",
        "  quant_num = 300\n",
        "  for i in range(quant_num):\n",
        "    pick_me = random.choice(dataset_list)\n",
        "    print(pick_me)\n",
        "    image = tf.io.read_file(pick_me)\n",
        "\n",
        "    if pick_me.endswith('.jpg') or pick_me.endswith('.JPG') or pick_me.endswith('.jpeg'):\n",
        "      image = tf.io.decode_jpeg(image, channels=3)\n",
        "    elif pick_me.endswith('.png'):\n",
        "      image = tf.io.decode_png(image, channels=3)\n",
        "    elif pick_me.endswith('.bmp'):\n",
        "      image = tf.io.decode_bmp(image, channels=3)\n",
        "\n",
        "    image = tf.image.resize(image, [width, height])  # TO DO: Replace 300s with an automatic way of reading network input size\n",
        "    image = tf.cast(image / 255., tf.float32)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "    yield [image]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtu98mzebEj"
      },
      "source": [
        "Finally, we'll initialize the TFLiteConverter module, point it at the TFLite graph we generated in Step 6, and provide it with the representative dataset generator function we created in the previous code block. We'll configure the converter to quantize the model's weight values to INT8 format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ox0bGDWds_Ce"
      },
      "outputs": [],
      "source": [
        "# Initialize converter module\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
        "print(\"initialized converter\")\n",
        "# This enables quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# This sets the representative dataset for quantization\n",
        "converter.representative_dataset = representative_data_gen\n",
        "# This ensures that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "# These set the input tensors to uint8 and output tensors to float32\n",
        "converter.inference_input_type = tf.uint8\n",
        "converter.inference_output_type = tf.float32\n",
        "print(\"begin conversion\")\n",
        "tflite_model = converter.convert()\n",
        "print(\"conversion complete\")\n",
        "\n",
        "with open(FINALOUTPUTFOLDER+'/limelight_neural_detector_8bit.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFsuasvxFHo8"
      },
      "source": [
        "# 7. Compile Model for Limelight & Download\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peawOI_z0DHt"
      },
      "source": [
        "Install Coral Compiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mUd_SNC0JSq0"
      },
      "outputs": [],
      "source": [
        "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "! sudo apt-get update\n",
        "! sudo apt-get install edgetpu-compiler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usfmdtSiJuuC"
      },
      "source": [
        "Compile the previously-generated 8-bit model for Google Coral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mULCY0nb0ahH"
      },
      "outputs": [],
      "source": [
        "!cd {FINALOUTPUTFOLDER} && pwd && edgetpu_compiler limelight_neural_detector_8bit.tflite && pwd && mv limelight_neural_detector_8bit_edgetpu.tflite limelight_neural_detector_coral.tflite && rm limelight_neural_detector_8bit_edgetpu.log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqGy2FgzKomN"
      },
      "source": [
        "Zip models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nCdUouYJjQM"
      },
      "outputs": [],
      "source": [
        "!rm {HOMEFOLDER}limelight_detectors.zip\n",
        "!zip -r {HOMEFOLDER}limelight_detectors.zip {FINALOUTPUTFOLDER}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHgbpkQue-ZR"
      },
      "source": [
        "Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmjqvKuuK8ZR"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(HOMEFOLDER+'limelight_detectors.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "05N8FeXHcQp3",
        "xmROIG9zaS9G",
        "eGEUZYAMEZ6f",
        "-19zML6oEO7l",
        "kPg8oMnQDYKl",
        "VTyqlXFTJ0Uv",
        "XFsuasvxFHo8"
      ],
      "gpuClass": "premium",
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "dac6b1a68a930bf8a24417228a96ab80b19f2aa97bc2d428affc356154b4740f"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53ae8c4f9cd24c26b75d65ab7ccafead": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f21aed3e9f7421e888e72de00d98a97",
              "IPY_MODEL_bd31017e380b4ef19bc25f8fe077327a",
              "IPY_MODEL_6a0602404ee24a4f87850f8d8b6832e2"
            ],
            "layout": "IPY_MODEL_8264eebf02704d2193bd372d715f7490"
          }
        },
        "7f21aed3e9f7421e888e72de00d98a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79a08daed1b84f6299609b3c4c42886e",
            "placeholder": "​",
            "style": "IPY_MODEL_21e895fbee9c42ad8180b8b5a8528f23",
            "value": ""
          }
        },
        "bd31017e380b4ef19bc25f8fe077327a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "GridBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "GridBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "GridBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5eaf87940d6a4b3db612b426b77f6e32",
              "IPY_MODEL_2a8322924ebd4d5fa1c7770fb48c359e",
              "IPY_MODEL_eb0a9df4c05e411b95027f2147105ad2"
            ],
            "layout": "IPY_MODEL_84e80be945684eabb5d7714f16aefb2d"
          }
        },
        "6a0602404ee24a4f87850f8d8b6832e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0becbe3f6ab4c7c8c29dcea60b12961",
              "IPY_MODEL_cbd958053d0f41108706cfc348fc5671",
              "IPY_MODEL_2da585aebf474d3da9d76610d3601b1b"
            ],
            "layout": "IPY_MODEL_4e9d35a17ad74b42b73a10eb41ebe697"
          }
        },
        "8264eebf02704d2193bd372d715f7490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "500px"
          }
        },
        "79a08daed1b84f6299609b3c4c42886e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "none",
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21e895fbee9c42ad8180b8b5a8528f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5eaf87940d6a4b3db612b426b77f6e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "/content/gdrive/MyDrive",
              "/content/gdrive",
              "/content",
              "/"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_a1472b4742154086be39d546dc4a360c",
            "style": "IPY_MODEL_2e02fcf1c9474bdc825b47637ab4755e"
          }
        },
        "2a8322924ebd4d5fa1c7770fb48c359e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_e4a5692326ee4840b34682ded1883ab2",
            "placeholder": "output filename",
            "style": "IPY_MODEL_dde2476c923b446281bd90cb2f036b16",
            "value": "Infinite-recharge-balls-yolov5.v1i.tfrecord.zip"
          }
        },
        "eb0a9df4c05e411b95027f2147105ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "SelectModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "SelectModel",
            "_options_labels": [
              "📁 #SAND",
              "📁 ..",
              "📁 Chromebook Wallpaper",
              "📁 Classroom",
              "📁 Classroom (1)",
              "📁 Colab Notebooks",
              "📁 Family docs",
              "📁 Gmail Templates",
              "📁 Google AI Studio",
              "📁 Google Earth",
              "📁 HOME",
              "📁 Secrets",
              "📁 Sleep as Android",
              "📁 StableSwarmUI",
              "📁 Stack",
              "📁 appsheet",
              "01:06424 Physics S1 - 06424-00002\n7:30 AM-8:32 AM....gsheet",
              "About Me!.gslides",
              "AoW-2324_04-Cell-Phone-Ban- (1).pdf",
              "AoW-2324_04-Cell-Phone-Ban-.pdf",
              "Apollo: God of Light and Music.gslides",
              "Boss 2.0.gscript",
              "Copy of Ritesh Raj Arul Selvan - Harlem Renaissance Poetry Essay.gdoc",
              "Copy of Students Tracker FEDS 23-24 (1).gsheet",
              "Copy of Students Tracker FEDS 23-24.gsheet",
              "Creating a New Budget Student Assignment .gdoc",
              "FEDS201.gsite",
              "FRC Programming Training Agenda (2 Days, 3 Hours per Week, Progressive Difficulty).gdoc",
              "FRC note trejectry .gsheet",
              "Faith Skit.gdoc",
              "Forgiveness  Character of the prodigal son.gdoc",
              "Generate facts about Taj mahal, lotus Temple and gateway of India.gdoc",
              "Happy B-DAY - Ritesh.mp4",
              "IMG_20230224_093918.jpg",
              "INNOV.gsite",
              "Infinite-recharge-balls-yolov5.v1i.tfrecord.zip",
              "MOOD_tracker.gsheet",
              "Messages.gsheet",
              "Methology Proj.gslides",
              "Movie Promo.gdoc",
              "My Googlesheets form.gsheet",
              "My audio model.tm",
              "PXL_20230921_214203486.jpg",
              "PYINTEL_SERVER.gscript",
              "PYINTEL_UNIT.gscript",
              "PYNTEL_BACKEND.gsheet",
              "Photo album.gslides",
              "Pyintel-On-Client.gscript",
              "R&D.gscript",
              "Recipe showcase.gslides",
              "Recreation of the Bug.gsheet",
              "Resume.gdoc",
              "Ritesh & Alfrin – Forgiveness.gdoc",
              "Scientific Principals of Obesity.gdoc",
              "Screenshot 2024-08-12 10.44.42 PM.png",
              "Sources - Why we hate each other on the internet....gdoc",
              "The Digital Divide.gslides",
              "The Scientific Principals of Obesity.gdoc",
              "Training proposal.gdoc",
              "Understanding Emotions.gdoc",
              "Untitled Jam.gjam",
              "Untitled document (1).gdoc",
              "Untitled document (2).gdoc",
              "Untitled document (3).gdoc",
              "Untitled document (4).gdoc",
              "Untitled document (5).gdoc",
              "Untitled document.gdoc",
              "Untitled document.pdf",
              "Untitled map.gmap",
              "Untitled presentation (1).gslides",
              "Untitled presentation (2).gslides",
              "Untitled presentation (3).gslides",
              "Untitled presentation (4).gslides",
              "Untitled presentation (5).gslides",
              "Untitled presentation (6).gslides",
              "Untitled presentation (7).gslides",
              "Untitled presentation.gslides",
              "Untitled project.gscript",
              "Untitled spreadsheet (1).gsheet",
              "Untitled spreadsheet (2).gsheet",
              "Untitled spreadsheet.gsheet",
              "Untitled0.ipynb",
              "VersionValidator.gscript",
              "Visa Docs - 02.pdf",
              "What is the recommended graphics card and processor, If in wanted to run fine tuned flacon7b model locally in a machine .gsheet",
              "WhatsApp Chat with Keshia.txt",
              "WhatsApp Chat with ✨The Chosen Ones ✨.txt",
              "Youth-Skit-Act3_Scene1.als",
              "Youth-Skit-Act3_Scene1.wav",
              "Youth-Skit-Act3_Scene1.wav.asd",
              "Youth-Skit-Act3_Scene1.zip",
              "Youth-Skit-Act_Scene-2.als",
              "Youth-Skit-Scene-3.als",
              "Youth-Skit-Scene-3.zip",
              "create a document on my keyowrds and yeah, other....gdoc",
              "i can't see the image so lets make use of colab generate a pythjon script to crate te pic and show it.gdoc"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "SelectView",
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "index": 35,
            "layout": "IPY_MODEL_e2271f199d564c2f9b7ed191688eaf21",
            "rows": 8,
            "style": "IPY_MODEL_2153a994e98141b1bdb7e850fcca8581"
          }
        },
        "84e80be945684eabb5d7714f16aefb2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "none",
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": "0px 0px",
            "grid_row": null,
            "grid_template_areas": "\n                    'pathlist filename'\n                    'dircontent dircontent'\n                    ",
            "grid_template_columns": "60% 40%",
            "grid_template_rows": "auto auto",
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "c0becbe3f6ab4c7c8c29dcea60b12961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Change",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a43c305d6b24411ea43b382b85f6e46b",
            "style": "IPY_MODEL_9f121a4fba364e4b959defcd412fa30c",
            "tooltip": ""
          }
        },
        "cbd958053d0f41108706cfc348fc5671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Cancel",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_309f6b9c90074ee5a6394b87c757aa94",
            "style": "IPY_MODEL_799f079d3b304381822c794487192035",
            "tooltip": ""
          }
        },
        "2da585aebf474d3da9d76610d3601b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "BoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "BoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "BoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54a9ec73bb5848558026ebcc770c8e4e"
            ],
            "layout": "IPY_MODEL_5ee6ae42e9a74992b5fda023a6b3af40"
          }
        },
        "4e9d35a17ad74b42b73a10eb41ebe697": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "a1472b4742154086be39d546dc4a360c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": "pathlist",
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "2e02fcf1c9474bdc825b47637ab4755e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4a5692326ee4840b34682ded1883ab2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": "filename",
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "dde2476c923b446281bd90cb2f036b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2271f199d564c2f9b7ed191688eaf21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": "dircontent",
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "2153a994e98141b1bdb7e850fcca8581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a43c305d6b24411ea43b382b85f6e46b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "6em",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "6em"
          }
        },
        "9f121a4fba364e4b959defcd412fa30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "309f6b9c90074ee5a6394b87c757aa94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "none",
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": "6em",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "6em"
          }
        },
        "799f079d3b304381822c794487192035": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "54a9ec73bb5848558026ebcc770c8e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4953f6b4fde45bdb1835abc6327ebd1",
            "placeholder": "",
            "style": "IPY_MODEL_41c63fcf14c54ee8b5d4c714587ed5ea",
            "value": "<span style=\"color:orange;\">/content/gdrive/MyDrive/Infinite-recharge-balls-yolov5.v1i.tfrecord.zip</span>"
          }
        },
        "5ee6ae42e9a74992b5fda023a6b3af40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": "auto",
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4953f6b4fde45bdb1835abc6327ebd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "0 0 0 1em",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41c63fcf14c54ee8b5d4c714587ed5ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}